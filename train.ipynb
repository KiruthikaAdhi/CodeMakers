{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install --upgrade tensorflow",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting tensorflow\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/d5/38cd4543401708e64c9ee6afa664b936860f4630dd93a49ab863f9998cd2/tensorflow-1.11.0-cp36-cp36m-manylinux1_x86_64.whl (63.0MB)\n\u001b[K    100% |████████████████████████████████| 63.0MB 49kB/s  eta 0:00:01    18% |██████                          | 11.6MB 4.8MB/s eta 0:00:11    24% |███████▊                        | 15.2MB 20.2MB/s eta 0:00:03    40% |████████████▉                   | 25.3MB 3.9MB/s eta 0:00:10    57% |██████████████████▎             | 36.0MB 8.0MB/s eta 0:00:04██████████████████▋     | 52.3MB 11.4MB/s eta 0:00:01ta 0:00:01███████████▎| 61.4MB 8.1MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorflow) (1.15.2)\nCollecting keras-preprocessing>=1.0.3 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/fc/94/74e0fa783d3fc07e41715973435dd051ca89c550881b3454233c39c73e69/Keras_Preprocessing-1.0.5-py2.py3-none-any.whl\nCollecting absl-py>=0.1.6 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/ef/1fa0376563b1e0495301ada8e881d88b7ebfda433f6b31f44447fe6ef795/absl-py-0.6.0.tar.gz (93kB)\n\u001b[K    100% |████████████████████████████████| 102kB 3.7MB/s a 0:00:011\n\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\nRequirement already satisfied, skipping upgrade: six>=1.10.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorflow) (1.11.0)\nCollecting setuptools<=39.1.0 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n\u001b[K    100% |████████████████████████████████| 573kB 3.6MB/s ta 0:00:011\n\u001b[?25hCollecting gast>=0.2.0 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\nRequirement already satisfied, skipping upgrade: wheel>=0.26 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorflow) (0.30.0)\nCollecting tensorboard<1.12.0,>=1.11.0 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/2f/4d788919b1feef04624d63ed6ea45a49d1d1c834199ec50716edb5d310f4/tensorboard-1.11.0-py3-none-any.whl (3.0MB)\n\u001b[K    100% |████████████████████████████████| 3.0MB 1.3MB/s ta 0:00:01\n\u001b[?25hCollecting protobuf>=3.6.0 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/f9/28787754923612ca9bfdffc588daa05580ed70698add063a5629d1a4209d/protobuf-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n\u001b[K    100% |████████████████████████████████| 1.1MB 1.6MB/s ta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorflow) (1.15.0)\nCollecting keras-applications>=1.0.5 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl (44kB)\n\u001b[K    100% |████████████████████████████████| 51kB 2.8MB/s ta 0:00:011\n\u001b[?25hCollecting astor>=0.6.0 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\nRequirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow) (0.12.2)\nCollecting markdown>=2.6.8 (from tensorboard<1.12.0,>=1.11.0->tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\n\u001b[K    100% |████████████████████████████████| 92kB 3.2MB/s ta 0:00:011\n\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from keras-applications>=1.0.5->tensorflow) (2.8.0)\nBuilding wheels for collected packages: absl-py, termcolor, gast\n  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/91/3f/fc/04598e99d64928bec676e07245b132e985df067cf5d469c460\n  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\nSuccessfully built absl-py termcolor gast\n\u001b[31mkeras 2.2.2 has requirement keras_applications==1.0.4, but you'll have keras-applications 1.0.6 which is incompatible.\u001b[0m\n\u001b[31mkeras 2.2.2 has requirement keras_preprocessing==1.0.2, but you'll have keras-preprocessing 1.0.5 which is incompatible.\u001b[0m\nInstalling collected packages: keras-preprocessing, absl-py, termcolor, setuptools, gast, protobuf, markdown, tensorboard, keras-applications, astor, tensorflow\n  Found existing installation: Keras-Preprocessing 1.0.2\n    Uninstalling Keras-Preprocessing-1.0.2:\n      Successfully uninstalled Keras-Preprocessing-1.0.2\n  Found existing installation: setuptools 40.4.3\n    Uninstalling setuptools-40.4.3:\n      Successfully uninstalled setuptools-40.4.3\n  Found existing installation: protobuf 3.4.1\n    Uninstalling protobuf-3.4.1:\n      Successfully uninstalled protobuf-3.4.1\n  Found existing installation: Keras-Applications 1.0.4\n    Uninstalling Keras-Applications-1.0.4:\n      Successfully uninstalled Keras-Applications-1.0.4\n  Found existing installation: tensorflow 1.1.0\n    Uninstalling tensorflow-1.1.0:\n      Successfully uninstalled tensorflow-1.1.0\nSuccessfully installed absl-py-0.6.0 astor-0.7.1 gast-0.2.0 keras-applications-1.0.6 keras-preprocessing-1.0.5 markdown-3.0.1 protobuf-3.6.1 setuptools-39.1.0 tensorboard-1.11.0 tensorflow-1.11.0 termcolor-1.1.0\n\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport tensorflow as tf\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "trainFile = 'trainDataset.csv'\ntrainData = pd.read_csv(trainFile)\nprint(trainData.shape)\nprint(trainData.head())\n\n\n# x = np.loadtxt(trainFile,delimiter = ',')[:, :-1]\n# print(x)\n# y = np.loadtxt(trainFile,delimiter = ',')[:, -1:]\n# print(y)\n#data = read_data_sets(trainFile)\n#print(data)\n# trainingSteps = 1000\n# total = 5000\n# featureCol = [tf.feature_column.numeric_column(\"\", shape = (75,) )]\n# hiddenUnits = [100, 150, 100, 50]\n# classes = 2\n# modelDir = 'model'\n# classifierConfig = tf.estimator.RunConfig(save_checkpoints_secs = None, save_checkpoints_steps = trainingSteps)\n# classifier = tf.estimator.DNNClassifier(feature_columns = featureCol,\n#                                             hidden_units = hiddenUnits,\n#                                             n_classes = classes,\n#                                             model_dir = modelDir,\n#                                             config = classifierConfig)\n",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(90252, 76)\n    c1   c2   c3   c4   c5   c6   c7   c8   c9  c10   ...    c67  c68  c69  \\\n0  116  121  128  122  124  133  121  122  132  119   ...    126  127  139   \n1  128  105   93  131  115   96  138  126  100   58   ...    132  111   95   \n2   81   96   75  141  147  123  193  196  192  195   ...    198  202  199   \n3   49   86   60   80   80   80   65   69   77   63   ...     67   70   76   \n4   84   94   71  116  109   94  137  127  105  127   ...    108  115   91   \n\n   c70  c71  c72  c73  c74  c75  isroad  \n0  124  126  136  120  125  136       1  \n1  113  102   82  101   84   79       0  \n2  194  193  190  116  129  109       0  \n3   63   64   73   70   70   79       1  \n4  109  114   89  116  116   90       0  \n\n[5 rows x 76 columns]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "target = trainData.isroad\nprint(target)\nfeatures = trainData.drop('isroad', axis = 1)\nprint(features)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0        1\n1        0\n2        0\n3        1\n4        0\n5        0\n6        1\n7        0\n8        0\n9        1\n10       0\n11       0\n12       1\n13       0\n14       0\n15       1\n16       0\n17       0\n18       1\n19       0\n20       0\n21       1\n22       0\n23       0\n24       1\n25       0\n26       0\n27       1\n28       0\n29       0\n        ..\n90222    1\n90223    0\n90224    0\n90225    1\n90226    0\n90227    0\n90228    1\n90229    0\n90230    0\n90231    1\n90232    0\n90233    0\n90234    1\n90235    0\n90236    0\n90237    1\n90238    0\n90239    0\n90240    1\n90241    0\n90242    0\n90243    1\n90244    0\n90245    0\n90246    1\n90247    0\n90248    0\n90249    1\n90250    0\n90251    0\nName: isroad, Length: 90252, dtype: int64\n        c1   c2   c3   c4   c5   c6   c7   c8   c9  c10 ...   c66  c67  c68  \\\n0      116  121  128  122  124  133  121  122  132  119 ...   138  126  127   \n1      128  105   93  131  115   96  138  126  100   58 ...    87  132  111   \n2       81   96   75  141  147  123  193  196  192  195 ...   193  198  202   \n3       49   86   60   80   80   80   65   69   77   63 ...    75   67   70   \n4       84   94   71  116  109   94  137  127  105  127 ...   102  108  115   \n5      255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n6      155  157  160  159  158  159  159  161  164  163 ...   153  150  151   \n7      255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n8       41   47   36   35   35   34   80   74   55   55 ...    44   68   64   \n9       39   50   50   57   55   55   65   61   60   58 ...    61   62   65   \n10     108  121   73  116  116   71  120  126   72  105 ...    79  124  122   \n11     255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n12     139  142  137  144  140  131  149  154  122  132 ...   153  146  146   \n13     205  198  175  176  169  141  181  174  141  172 ...   143  184  175   \n14      66   73   59   53   61   45   63   70   47   59 ...    57   62   68   \n15     150  151  163  147  153  160  148  152  159  150 ...   161  143  144   \n16     255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n17     255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n18      63   61   68   84   73   81   85   79   83   80 ...   165  153  164   \n19      65   61   57   70   69   71   82   79   82   89 ...    64   73   73   \n20     138  127   93  118  120   80  135  126   90  113 ...    68  125  121   \n21     178  188  183  170  181  178  178  185  182  151 ...   163  162  170   \n22      56   84   47   43   65   45   69   84   50   60 ...    32   62   88   \n23     108  100   86   83  101   72   74   94   67   89 ...    58   97  114   \n24     121  124  133  122  125  134  122  127  137  114 ...   130  116  118   \n25      53   60   48   17   29   31   24   38   32   24 ...    62   92  119   \n26     255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n27     154  156  163  165  173  178  168  173  177  164 ...   174  164  169   \n28      75   81   64   72   82   60   73   78   62  102 ...    73   85   93   \n29     136  118  101  121  114   92  115  111   89  155 ...    99  124  105   \n...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ... ...   ...  ...  ...   \n90222  154  152  141  154  152  141  154  152  141  154 ...   141  145  144   \n90223    0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n90224    0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n90225  127  134  134  127  135  134  135  144  130  135 ...   130  132  140   \n90226  145  141  111  145  141  111  144  141  110  144 ...   105  137  135   \n90227  137  130   96  137  130   94  137  130   95  120 ...   106  141  134   \n90228    0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n90229    0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n90230  223  219  206  223  219  206  223  219  206  221 ...   199  213  212   \n90231  154  153  149  153  153  148  153  153  150  149 ...   137  143  141   \n90232  144  152  136  143  151  137  138  146  130   94 ...   165  162  167   \n90233   71   74   79   70   73   78   70   73   78   70 ...    80   70   74   \n90234  163  170  163  154  151  133  154  151  133  154 ...   161  163  169   \n90235    0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n90236  108   85   70  106   83   68   96   78   63   96 ...    73  110   85   \n90237  115  119  115  115  119  116  115  119  116  116 ...   117  120  122   \n90238  172  174  171  163  165  162  163  165  162  163 ...    90  125  103   \n90239  158  143  115  160  146  120  160  146  120  160 ...   116  159  143   \n90240    0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n90241  110   86   66  109   85   65  109   85   66  106 ...    70  109   84   \n90242    0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n90243  162  165  160  162  166  160  162  165  159  150 ...   157  160  162   \n90244   29   42   31   34   39   33   34   39   33   34 ...    39   52   49   \n90245   86   67   57   80   68   52   69   61   48   63 ...    58  121   92   \n90246  146  143  132  147  143  132  148  145  133  126 ...   137  148  145   \n90247  166  144  112  165  143  110  166  143  112  165 ...    90  132  107   \n90248    0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n90249  176  178  163  175  177  163  174  176  162  172 ...   140  159  155   \n90250   70   62   56   49   44   43   52   45   45   52 ...    60   65   61   \n90251    0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n\n       c69  c70  c71  c72  c73  c74  c75  \n0      139  124  126  136  120  125  136  \n1       95  113  102   82  101   84   79  \n2      199  194  193  190  116  129  109  \n3       76   63   64   73   70   70   79  \n4       91  109  114   89  116  116   90  \n5      255  255  255  255  255  255  255  \n6      157  148  150  150  141  143  147  \n7      255  255  255  255  255  255  255  \n8       48  112   96   80  135  117   86  \n9       71   70   70   77   65   68   71  \n10      78  102  112   69  107  117   74  \n11     255  255  255  255  255  255  255  \n12     150  153  155  156  156  156  157  \n13     143  146  142  108  143  136  104  \n14      52   61   66   50   49   60   45  \n15     155  143  158  165  149  156  168  \n16     255  255  255  255  255  255  255  \n17     255  255  255  255  255  255  255  \n18     158  121  123  132   97   91   99  \n19      72   79   68   78   63   58   64  \n20      86  107  115   79  120  119   83  \n21     168  159  168  169  153  163  161  \n22      54   65   94   59   57   92   53  \n23      74   87  114   74   86  111   71  \n24     130  108  112  122  110  114  122  \n25      81   93  116   82   94  115   85  \n26     255  255  255  255  255  255  255  \n27     177  142  149  149   50   72   61  \n28      69   66   69   56   77   85   65  \n29      90  116  113   90  102   91   81  \n...    ...  ...  ...  ...  ...  ...  ...  \n90222  142  145  144  142  146  144  141  \n90223    0    0    0    0    0    0    0  \n90224    0    0    0    0    0    0    0  \n90225  131  132  140  131  132  140  131  \n90226  107  151  148  117  151  148  117  \n90227  104  130  125   92  130  125   93  \n90228    0    0    0    0    0    0    0  \n90229    0    0    0    0    0    0    0  \n90230  199  204  204  193  188  190  180  \n90231  139  144  142  139  144  142  139  \n90232  157  114  126   99  115  127  100  \n90233   80   70   74   80   69   73   79  \n90234  161  164  169  160  159  160  151  \n90235    0    0    0    0    0    0    0  \n90236   70  110   86   70  110   86   70  \n90237  117  120  122  115  117  119   94  \n90238   89  125  103   90  124  109   94  \n90239  116  159  143  116  159  143  116  \n90240    0    0    0    0    0    0    0  \n90241   70  107   83   68  102   81   66  \n90242    0    0    0    0    0    0    0  \n90243  156  150  142  128  151  142  129  \n90244   39   52   50   40   50   48   40  \n90245   76  106   80   68  110   82   63  \n90246  138  144  142  131  142  140  129  \n90247   88  131  106   88  156  136  110  \n90248    0    0    0    0    0    0    0  \n90249  139  158  153  137  149  133  110  \n90250   55   73   70   62   72   70   63  \n90251    0    0    0    0    0    0    0  \n\n[90252 rows x 75 columns]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_train, x_test, y_train, y_test = train_test_split( features, target, test_size=0.2)\nprint(x_train)\nprint(x_test)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "        c1   c2   c3   c4   c5   c6   c7   c8   c9  c10 ...   c66  c67  c68  \\\n15275   76   78   65   81   77   69  185  166  124  115 ...   110   43   48   \n53539  174  176  157  132  134  122  172  173  153  206 ...    86  102  104   \n18974   14   28   16   45   71   36   61   88   52   22 ...    31   97   73   \n11350  110   80   78  117   97   81   90   74   76   92 ...   100  150  129   \n70844  217  213  186  207  206  176  188  182  167  177 ...   197  196  202   \n5690    78   75   72   72   71   61   69   68   61   97 ...    81   81   74   \n12040  170  160  131  145  134  121  130  117  108  147 ...    90  115  109   \n24106   51   49   38   68   63   53   66   66   58   64 ...    43   55   59   \n86743  139  146  105  139  147   99  123  127   92  135 ...   100  148  159   \n18156   58   62   68   65   67   78   68   69   76   88 ...   155  141  140   \n67734   22   42   31   12   24   19   12   15   16   15 ...    17   15   22   \n2606    96   79   74   75   66   61   78   66   61   78 ...    97   86   73   \n87820  165  162  134  165  157  134  169  164  139  169 ...   136  172  167   \n38928  206  189  195  198  168  191  104   99  114   98 ...   202  185  190   \n77693   83   97   62   79   93   49   68   97   53   87 ...    47   70   91   \n39216  149  149  137  136  135  131  129  126  123  135 ...   114  136  139   \n62682  162  158  135  164  163  141  167  166  150  166 ...   118  165  160   \n21128  121   97   90   77   66   60   90   65   58  102 ...    73  115   83   \n57983   88   98   77   80   92   64   71   82   57   71 ...    57   82   86   \n23231  112  114   96  103  121   86   61   86   60   38 ...    70   74   94   \n43509  130  130  125  132  129  126  132  129  122  124 ...   125  130  131   \n23813  205  198  174  199  197  178  207  200  179   81 ...   113  137  133   \n24942  100  104   92   80   78   85   89   84   92  111 ...    96   98   82   \n89729  151  133  109  147  127  106  147  127  106  147 ...    99  133  115   \n57756  124  132  120  129  126  120  130  127  116  124 ...   100  153  146   \n81332   40   57   42   24   38   28   27   36   35   22 ...    37   29   36   \n82366   49   57   47   56   66   48   60   77   56   58 ...    76  112   97   \n19067  107   93   90   97   82   79   64   60   59   39 ...    50   64   62   \n14927   80   74   77   89   74   69   98   85   76   69 ...    56  112  112   \n39435  139  125  110  126  131  127  121  120  123  121 ...   119  119  123   \n...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ... ...   ...  ...  ...   \n27525  133  109   80  126  114   86   86   74   71   91 ...    47   47   51   \n23093   90   75   68  132  100   78  116   88   77   47 ...    70   83   68   \n49859  138  119   98  102  105   76  152  140  105  152 ...    93  135  132   \n81952   40   50   42   58   60   52   62   62   54   56 ...    71   74   79   \n79886   57   70   45   43   52   34   53   53   39   53 ...    47   41   46   \n76190   40   46   33   21   23   21   23   25   28   27 ...    34   43   58   \n17380   67   64   55   65   61   50   41   46   39   48 ...    49   51   54   \n12300  140  141  145  138  142  146  133  134  136   71 ...   150  142  147   \n57242  255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n78916  113   93   80   96   79   68   88   77   69  133 ...    59  111   79   \n33047   65   68   50   61   61   48   50   58   46   60 ...    44   56   62   \n45926  120  137   91  109  121   89   80   96   71   66 ...   104  140  130   \n58830  128  132  125  106  112  110  102  107  108   99 ...   111  112  111   \n50145   52   50   41   31   34   33   19   31   30   30 ...    45   50   59   \n7922    41   46   42   35   40   38   32   42   39   46 ...    22   26   45   \n40076   66   65   65   72   78   66   92   92   83  115 ...    75   61   63   \n39057  211  203  207  205  211  203   86   92  102   94 ...   115  105  106   \n4150   218  209  176  221  213  181  208  200  162  207 ...   142  186  172   \n84668   47   55   57   84   91  104   94   97  107  105 ...    78   66   65   \n51521   31   40   25   29   39   26   30   41   27   29 ...    29   28   38   \n14803   50   41   41   84   65   57   65   51   42   55 ...    50   42   44   \n62679  255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n23163  131  131  104  134  134  135  134  131  136  134 ...   128  129  133   \n13172  190  198  189  207  212  199  206  211  201  209 ...   118  109  127   \n65479   41   47   48   33   44   39   23   34   29   24 ...    44   30   41   \n4001   255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n84498  124  124  137  197  199  189  126  133  145  197 ...   142  167  167   \n48526  255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n64057  255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n83922   87   91   99   89   95  104   88   96  109   87 ...   111   96  102   \n\n       c69  c70  c71  c72  c73  c74  c75  \n15275   40  110  112   77   82   83   76  \n53539  111   94   97  102  108  102  117  \n18974   49   28   45   22   30   56   32  \n11350  103  105   90   84  118   92   88  \n70844  197  196  201  196  204  208  201  \n5690    68   96   94   82  113  107   85  \n12040   94  119  114   99  146  136  114  \n24106   51   61   60   49   58   57   43  \n86743  112  141  150  104  137  151   99  \n18156  139  151  154  151  163  152  136  \n67734   22   14   27   21   18   29   21  \n2606    70   71   64   54   57   49   43  \n87820  143  173  166  141  173  167  143  \n38928  186  109  110  114  101  103  108  \n77693   52   72   94   46   74  101   55  \n39216  125  127  128  126  141  136  132  \n62682  140  140  140  115  136  126  110  \n21128   70   70   62   53  138  104   93  \n57983   64   84   78   64   74   67   63  \n23231   66   69   93   63   77   99   75  \n43509  118  138  133  127  128  131  121  \n23813  101   83   76   80   97   91   85  \n24942   99  100   88   96   93   96  102  \n89729   98  134  116   98  152  134  110  \n57756  121  149  142  127  148  148  125  \n81332   31   31   38   32   25   34   26  \n82366   81   98   88   70   97   81   73  \n19067   53   91   86   74  106   99   87  \n14927   71  116  117   82  136  132   86  \n39435  118  119  122  116  127  131  125  \n...    ...  ...  ...  ...  ...  ...  ...  \n27525   45   57   53   41   64   57   49  \n23093   51   52   50   47   56   52   45  \n49859   93  137  128   96  139  134  101  \n81952   81   70   75   75   84   88   84  \n79886   38   60   55   41   31   36   25  \n76190   41   68  105   50   50   76   39  \n17380   45   60   60   52   55   58   54  \n12300  150  155  157  160  154  159  162  \n57242  255  255  255  255  255  255  255  \n78916   65  134   95   85  140  119  110  \n33047   49   60   63   54   63   62   55  \n45926   98  138  132  100  155  149  116  \n58830  113  101  101  108  108  107  111  \n50145   47   26   32   33   14   22   26  \n7922    26   27   45   27   30   49   30  \n40076   59   60   67   57   69   78   50  \n39057  110   99   97  104   87   88   96  \n4150   133  223  214  180  221  214  184  \n84668   58   43   48   50   47   56   55  \n51521   23   29   37   27   29   38   28  \n14803   36   31   42   21   27   39   23  \n62679  255  255  255  255  255  255  255  \n23163  127  129  129  132  129  135  133  \n13172   97  110  134   94  110  135   99  \n65479   30   40   52   40   42   63   42  \n4001   255  255  255  255  255  255  255  \n84498  169  113  114  131  205  207  192  \n48526  255  255  255  255  255  255  255  \n64057  255  255  255  255  255  255  255  \n83922  113   92   99  108   97  104  114  \n\n[72201 rows x 75 columns]\n        c1   c2   c3   c4   c5   c6   c7   c8   c9  c10 ...   c66  c67  c68  \\\n31534  143  143  144  135  134  139  131  134  140  126 ...   197  152  157   \n78986   50   66   36   48   69   37   37   56   28   40 ...    12   31   47   \n7826   142  126  114   47   48   49  158  137  103  121 ...    32   78   84   \n39395   60   84   52   64   90   66   63   80   54   61 ...    61   73   94   \n38570   75   65   56   79   70   62   81   68   56   40 ...    47   67   65   \n23121  112   97  110   66   64   76   90   81   87   95 ...    53   59   52   \n20164   91   76   67   93   73   64   67   61   53  130 ...    55   85   66   \n21571   80   65   81   43   47   55   45   51   56   70 ...   162  153  162   \n67989  135  139  143  146  154  159  151  155  157  145 ...   211  216  215   \n10014  103  100  123  130  147  150  108  111  127  100 ...   135  130  138   \n16987   79  108   66   97  119   75   93  109   72   65 ...    49   67   97   \n19280   72   63   53   34   38   33   63   55   48   76 ...    45   68   67   \n79739   58   65   45   68   60   53   99   79   60  103 ...    34   64   68   \n35066  255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n37782  123  126  117  103  107  108   94   95   99  110 ...   126  124  122   \n83201   61   58   43   63   64   47   59   66   57   66 ...    68   31   43   \n18035   51   49   47   36   43   42   41   43   47   51 ...    59   60   60   \n73433  245  245  243  241  240  238  242  242  239  244 ...   243  242  242   \n9969    62   59   58   52   53   53   72   67   61   67 ...    67  130   98   \n53859  123  116  118  123  116  119  118  112  116  140 ...   117  124  127   \n65729   72   68   58   98   84   75   72   62   60   64 ...    42   60   57   \n13320  203  203  196  190  193  183  165  174  152   98 ...   200  199  201   \n83336   45   51   42   46   43   46   50   51   47   44 ...    84   74   78   \n64115  255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n73373  180  186  171  114  125  115  118  134  100  111 ...   165  164  168   \n43118   39   44   54  171  185  187  164  174  181  166 ...   201  181  193   \n61051  107  108   80   95   90   73  154  141  101  131 ...    94  127  120   \n71342   92   96  112  174  179  172   67   69   73   55 ...   132   49   54   \n87005  159  146  118  210  209  197  182  181  180  212 ...   174  206  197   \n36734   17   29   17   16   29   11   15   28   15   15 ...    19   15   29   \n...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ... ...   ...  ...  ...   \n61403   85   72   53   83   70   53   47   50   38   32 ...    38   65   60   \n47021  133  129  128   78   80   86   76   74   80  103 ...   121  122  134   \n30395   93   94   96   86   85   93  106   97  101  109 ...    83   74   66   \n65771   23   27   35   18   32   23   19   22   31   14 ...    21   16   29   \n78907   53   76   39   60   78   41   39   49   38   48 ...    42   42   42   \n19055   59   68   45   71   77   57   71   71   54   56 ...    62   93   95   \n28120  137  115   88  127  105   76   59   55   43   68 ...    50   44   47   \n34609   57   57   56   77   73   80   73   73   76   66 ...    75   59   59   \n8767    58   80   53   73   72   53   57   55   42   69 ...    58   37   53   \n22641   88   86   91   69   69   76  108  105   97  111 ...    94  139  118   \n55576   65   63   48   58   61   48   44   45   40   63 ...    42   50   49   \n31561   90   93   80   77  109   70   91  127   69   96 ...    47   46   51   \n4728   131  129  138  110  114  116   96  101  113  106 ...   139  146  147   \n76695  121  137  147  117  131  125  126  134  124  133 ...   157  151  157   \n9320   161  150  146  158  148  142  133  123  117  139 ...   108   96  102   \n79310  141  130  105  137  131  101  148  138  108  149 ...    97  147  137   \n8782   119  127  135  128  139  142  139  139  143  109 ...   146  128  140   \n81710  137  111   86  102   82   72   73   70   63   58 ...    58   66   63   \n90060  146  129  107  146  129  107  146  129  107  139 ...   111  143  130   \n87667  246  246  246  246  246  246  246  246  246  246 ...   245  246  246   \n31811   92   80   84  132  114  102  120  107  104  139 ...   119  137  125   \n2992   255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n58687  255  255  255  251  252  252  255  255  255  255 ...    70  251  251   \n75393  101   95   96   77   76   81  122  121  124  200 ...    75   96   97   \n36011  255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n12893   79  126   66  110  112   80   93  106   71  124 ...    81   74   75   \n25180   83   73   62  106  101   83  101   85   81  113 ...    56   69   62   \n4187    60   59   45   46   52   41   43   50   33   58 ...    58   75   85   \n34944  255  255  255  255  255  255  255  255  255  255 ...   255  255  255   \n17647   45   77   53   51   78   43   50   81   49   64 ...    46   49   80   \n\n       c69  c70  c71  c72  c73  c74  c75  \n31534  157  156  155  153  148  152  147  \n78986   17   21   36   15   16   30   12  \n7826    84  104  110  110   76  125  176  \n39395   72   84  109   71   96  120   78  \n38570   52   70   66   55   70   70   59  \n23121   55   74   67   63   78   64   68  \n20164   61   82   71   57   91   71   65  \n21571  164  145  150  155  152  155  160  \n67989  208  223  222  214  211  212  205  \n10014  148  113  110  137  136  138  148  \n16987   56   37   65   47   42   67   53  \n19280   52   91   80   65   93   70   66  \n79739   42   52   54   38   45   48   36  \n35066  255  255  255  255  255  255  255  \n37782  116  107  113  110  105  109  110  \n83201   44   75   73   60   62   64   49  \n18035   54   49   50   49   57   57   55  \n73433  238  245  244  242  244  243  240  \n9969    74  119   91   79   99   79   64  \n53859  126  131  137  126   69   75   75  \n65729   49   70   63   51   53   52   43  \n13320  195  202  203  196  202  201  200  \n83336   68   68   74   58   72   72   62  \n64115  255  255  255  255  255  255  255  \n73373  156   89   90   94  117  124  115  \n43118  195  167  176  183  170  181  189  \n61051   90  131  126   94  182  175  139  \n71342   59   60   63   64   82   87   85  \n87005  187  206  199  185  209  204  199  \n36734   16   15   28   16   16   28   17  \n...    ...  ...  ...  ...  ...  ...  ...  \n61403   41   38   35   23   27   32   22  \n47021  135  143  148  150  173  171  168  \n30395   81   77   76   83   68   61   66  \n65771   21   23   34   19   21   43   28  \n78907   37   37   38   37   35   39   31  \n19055   61   87   86   59   92   93   62  \n28120   36   57   57   40   43   45   36  \n34609   63   60   63   68   64   66   71  \n8767    41   46   46   42   46   46   40  \n22641   94  141  133   95  101   86   84  \n55576   40   51   55   39   69   65   51  \n31561   45   45   56   41   61   70   53  \n4728   145  144  157  147  164  170  155  \n76695  158  156  162  157  152  153  151  \n9320   104  105  106  107  109  108  111  \n79310  102  164  158  112  170  167  123  \n8782   150  135  150  154  125  131  140  \n81710   51   75   68   57   67   60   59  \n90060  111  136  128  113  125  123  119  \n87667  246  244  244  244  246  246  245  \n31811  121  165  154  132   98   89   97  \n2992   255  255  255  255  255  255  255  \n58687  251  255  255  255  255  255  255  \n75393  104  118  119  112  124  126  120  \n36011  255  255  255  255  255  255  255  \n12893   62   74   64   65   57   67   51  \n25180   60   76   71   70  102   86   80  \n4187    57   37   42   36   34   35   34  \n34944  255  255  255  255  255  255  255  \n17647   50   56   77   52   56   86   44  \n\n[18051 rows x 75 columns]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "numeric_columns = []\nfor i in range(1,76):\n    numeric_columns.append(\"c\"+str(i))\nprint(numeric_columns)\nnumeric_features = [ tf.feature_column.numeric_column(key = column)\n                    for column in numeric_columns]\nprint(numeric_features[0])\n    ",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'c15', 'c16', 'c17', 'c18', 'c19', 'c20', 'c21', 'c22', 'c23', 'c24', 'c25', 'c26', 'c27', 'c28', 'c29', 'c30', 'c31', 'c32', 'c33', 'c34', 'c35', 'c36', 'c37', 'c38', 'c39', 'c40', 'c41', 'c42', 'c43', 'c44', 'c45', 'c46', 'c47', 'c48', 'c49', 'c50', 'c51', 'c52', 'c53', 'c54', 'c55', 'c56', 'c57', 'c58', 'c59', 'c60', 'c61', 'c62', 'c63', 'c64', 'c65', 'c66', 'c67', 'c68', 'c69', 'c70', 'c71', 'c72', 'c73', 'c74', 'c75']\n_NumericColumn(key='c1', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "training_input_fn = tf.estimator.inputs.pandas_input_fn(\n                    x = x_train,\n                    y = y_train,\n                    batch_size = 32,\n                    shuffle = True,\n                    num_epochs = None    \n                    )\neval_input_fn =  tf.estimator.inputs.pandas_input_fn(\n                    x = x_test,\n                    y = y_test,\n                    batch_size = 32,\n                    shuffle = False,\n                    num_epochs = 1    \n                    )\n",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "trainingSteps = 1000\ntotal = 5000\nclassifierConfig = tf.estimator.RunConfig(save_checkpoints_secs = None, save_checkpoints_steps = trainingSteps)\nhiddenUnits = [100, 150, 100, 50]\nclasses = 2\nmodelDir = 'model'\n\nclassifier = tf.estimator.DNNClassifier(feature_columns = numeric_features,\n                                             hidden_units = hiddenUnits,\n                                             n_classes = classes,\n                                             model_dir = modelDir,\n                                             config = classifierConfig)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "INFO:tensorflow:Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb679261a90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "classifier.train( input_fn = training_input_fn, steps = 2000)\naccuracy = classifier.evaluate(input_fn = eval_input_fn, steps=1)['accuracy']\nprint(accuracy)",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": "INFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from model/model.ckpt-2000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Saving checkpoints for 2000 into model/model.ckpt.\nINFO:tensorflow:loss = 16.525541, step = 2001\nINFO:tensorflow:global_step/sec: 13.9601\nINFO:tensorflow:loss = 20.493784, step = 2101 (7.187 sec)\nINFO:tensorflow:global_step/sec: 13.5844\nINFO:tensorflow:loss = 19.857784, step = 2201 (7.350 sec)\nINFO:tensorflow:global_step/sec: 15.272\nINFO:tensorflow:loss = 16.412086, step = 2301 (6.564 sec)\nINFO:tensorflow:global_step/sec: 13.4675\nINFO:tensorflow:loss = 16.412678, step = 2401 (7.458 sec)\nINFO:tensorflow:global_step/sec: 13.7862\nINFO:tensorflow:loss = 10.689244, step = 2501 (7.223 sec)\nINFO:tensorflow:global_step/sec: 13.1095\nINFO:tensorflow:loss = 17.157284, step = 2601 (7.613 sec)\nINFO:tensorflow:global_step/sec: 12.8305\nINFO:tensorflow:loss = 11.590893, step = 2701 (7.809 sec)\nINFO:tensorflow:global_step/sec: 12.5576\nINFO:tensorflow:loss = 15.285962, step = 2801 (7.981 sec)\nINFO:tensorflow:global_step/sec: 13.8647\nINFO:tensorflow:loss = 12.140987, step = 2901 (7.246 sec)\nINFO:tensorflow:Saving checkpoints for 3000 into model/model.ckpt.\nINFO:tensorflow:global_step/sec: 6.40345\nINFO:tensorflow:loss = 11.011293, step = 3001 (15.578 sec)\nINFO:tensorflow:global_step/sec: 15.2538\nINFO:tensorflow:loss = 16.281242, step = 3101 (6.566 sec)\nINFO:tensorflow:global_step/sec: 12.7934\nINFO:tensorflow:loss = 13.892586, step = 3201 (7.798 sec)\nINFO:tensorflow:global_step/sec: 13.9841\nINFO:tensorflow:loss = 18.300495, step = 3301 (7.149 sec)\nINFO:tensorflow:global_step/sec: 13.2263\nINFO:tensorflow:loss = 12.324839, step = 3401 (7.847 sec)\nINFO:tensorflow:global_step/sec: 13.0961\nINFO:tensorflow:loss = 14.141102, step = 3501 (7.344 sec)\nINFO:tensorflow:global_step/sec: 14.1683\nINFO:tensorflow:loss = 12.65658, step = 3601 (7.036 sec)\nINFO:tensorflow:global_step/sec: 14.6163\nINFO:tensorflow:loss = 10.7681675, step = 3701 (6.855 sec)\nINFO:tensorflow:global_step/sec: 15.0102\nINFO:tensorflow:loss = 14.714923, step = 3801 (6.698 sec)\nINFO:tensorflow:global_step/sec: 14.3046\nINFO:tensorflow:loss = 13.927475, step = 3901 (6.946 sec)\nINFO:tensorflow:Saving checkpoints for 4000 into model/model.ckpt.\nINFO:tensorflow:Loss for final step: 16.036861.\nINFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\nWARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Starting evaluation at 2018-10-25-12:15:33\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from model/model.ckpt-4000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Evaluation [1/1]\nINFO:tensorflow:Finished evaluation at 2018-10-25-12:15:40\nINFO:tensorflow:Saving dict for global step 4000: accuracy = 0.8125, accuracy_baseline = 0.71875, auc = 0.8816425, auc_precision_recall = 0.7525784, average_loss = 0.39317778, global_step = 4000, label/mean = 0.28125, loss = 12.581689, precision = 0.6363636, prediction/mean = 0.3332402, recall = 0.7777778\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: model/model.ckpt-4000\n0.8125\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "predictions = list(classifier.predict(input_fn = eval_input_fn))\nfor i in range(100):\n    print(predictions[i]['class_ids'][0])",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "INFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from model/model.ckpt-4000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\n1\n0\n0\n0\n0\n1\n0\n1\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n1\n1\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n1\n0\n0\n1\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}